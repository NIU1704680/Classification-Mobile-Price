# -*- coding: utf-8 -*-
"""Classification Mobile Price.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ttWyCSZazAR4RGoJE3xiK7sF_u92r05t

# Mobile Price Classification

## 1. Objetivo del proyecto:

El objetivo de este proyecto es crear un clasificador de precios de teléfonos móviles en función de sus diferentes características técnicas (RAM, batería, cámara, almacenamiento, etc.). Usaremos el dataset Mobile Price Classification de Kaggle, el cual contiene múltiples atributos de hardware y una etiqueta que clasifica cada móvil en una de cuatro categorías de precio:

https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification

## 2. Dataset:

El dataset contiene un total de 21 atributs, explicados a continuacion:

- ID: ID del producte (valor enter)

- Battery_power: total d’energia que pot emmagatzemar la bateria (mAh) (valor enter)

- Blue: si té bluetooth (valor booleà: 0 = no, 1 = sí)

- Clock_speed: velocitat del microprocessador en GHz (valor decimal)

- Dual_sim: si té suport per a doble SIM (valor booleà: 0 = no, 1 = sí)

- Fc: resolució de la càmera frontal en megapíxels (valor enter)

- Fourth_gen: si suporta 4G (valor booleà: 0 = no, 1 = sí)

- Int_memory: memòria interna en GB (valor enter)

- M_dep: profunditat del mòbil en centímetres (valor decimal)

- Mobile_wt: pes del mòbil en grams (valor enter)

- N_cores: nombre de nuclis del processador (valor enter)

- Pc: resolució de la càmera posterior en megapíxels (valor enter)

- Px_height: alçada de la resolució de pantalla en píxels (valor enter)

- Px_width: amplada de la resolució de pantalla en píxels (valor enter)

- Ram: memòria RAM del dispositiu en MB (valor enter)

- Sc_h: alçada de la pantalla en polzades (valor enter)

- Sc_w: amplada de la pantalla en polzades (valor enter)

- Talk_time: autonomia de trucada màxima (hores) (valor enter)

- Three_g: si suporta 3G (valor booleà: 0 = no, 1 = sí)

- Touch_screen: si té pantalla tàctil (valor booleà: 0 = no, 1 = sí)

- Wifi: si té connexió WiFi (valor booleà: 0 = no, 1 = sí)

Por ultimo encontrabos nuestro atribujo objetivo (tarjet), el cual el modelo tendrá que predecir:

- Price_range: categoria de preu (0 = baix, 1 = mitjà, 2 = alt, 3 = molt alt)

## 3. Librerias utilizadas:
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import label_binarize
from sklearn.metrics import precision_recall_curve, auc, roc_curve
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split

"""## 4. Analisis del dataset:

### Carga del dataset:
"""

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')

"""### Primero miraremos que columnas tenemos y cuantas (utilizado para la explicación anterior del dataset). Para ello usaremos el len():"""

print("Nombre d'atributs:", len(train.columns))
print("Nombre d'atributs:", train.columns)

"""### Necesitamos hacer un analisis inicial de Nans. No sabemos si el dataset actual contiene Nans, por lo tanto usaremos info() que nos dirá cuantos valores rellenados tiene cada columna:"""

print(train.info())

"""Como podeos ver cada columna contiene 2000 valores rellenados, por lo tanto no hay Nans y no es necesario hacer un tratamiento de estos.

### Ahora para saber el tipo de valores que contiene cada una de las columnas utilizamos .dtypes y head():
"""

print(train.dtypes)
print(train.head())

"""### Para saber si es necesario normalizar los datos necesitamos saber el rango de valores que tiene cada columna. Si hay rangos muy diferentes necesitaremos hacer esta normalizacion:"""

print(train.describe())

"""Para verlo mas claro utilizamos un grafico:"""

# Calcular medias de todos los atributos excepto la clase
means = train.drop(columns=["price_range"]).mean()

# Gráfico
plt.figure(figsize=(14,6))
means.plot(kind="bar")
plt.title("Media de cada atributo del dataset")
plt.xlabel("Atributos")
plt.ylabel("Valor medio")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

"""### Con el objetivo de identificar qué atributos influyen más en el precio del dispositivo, calculamos la correlación entre la variable price_range y el resto de características del dataset."""

# Correlación de todas las columnas con price_range
correlation_with_target = train.corr()['price_range'].sort_values(ascending=False)

print(correlation_with_target)

plt.figure(figsize=(8, 10))
sns.barplot(x=correlation_with_target.values, y=correlation_with_target.index)
plt.title("Correlación de cada característica con price_range")
plt.xlabel("Correlación")
plt.ylabel("Características")
plt.show()

"""Como se puede observar, el atributo que presenta la mayor relación con la variable price_range es la memoria RAM, mostrando una correlación significativamente superior al resto.

## 5. Tratamiento de datos:

### Comenzaremos separando el atributo objetivo del resto:
"""

X = train.drop(['price_range'], axis=1)
y = train['price_range']

"""### Para ver como normalizar los datos haremos una prueba con tres tipos de normalizacion:"""

#Comparación de diferentes técnicas de normalización y estandarización

# Variables numericas con rangos muy diferentes
data = train[['ram', 'mobile_wt']]

# Escaladores
scalers = {
    "Original": data,
    "StandardScaler": pd.DataFrame(StandardScaler().fit_transform(data), columns=data.columns),
    "MinMaxScaler": pd.DataFrame(MinMaxScaler().fit_transform(data), columns=data.columns),
    "RobustScaler": pd.DataFrame(RobustScaler().fit_transform(data), columns=data.columns),
}

# Visualización comparativa
plt.figure(figsize=(12, 6))

for i, (name, scaled) in enumerate(scalers.items(), 1):
    plt.subplot(2, 2, i)
    sns.kdeplot(scaled['ram'], fill=True, label='ram', alpha=0.5)
    sns.kdeplot(scaled['mobile_wt'], fill=True, label='mobile_wt', alpha=0.5)
    plt.title(name)
    plt.legend()

plt.tight_layout()
plt.show()

"""Despues de ver que tanto RobustScaler, MinMaxScaler y StandardScaler dan valores muy parecidos nos quedaremos con RobustScaler.

### Normalizamos los datos:
"""

# Dividir los datos antes de escalar para evitar Data Leakage
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Aplicar RobustScaler
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train) # Ajustar el escalador solo con el conjunto de entrenamiento (el fit sirve para que aprenda parámetros de los datos de train)
X_test_scaled = scaler.transform(X_test) # Aplicar la misma transformación al conjunto de prueba (Transform solamente)

"""## 6. Primer modelo: LogisticRegression

### He decidido elegir como primer modelo la Regression logistica por su sencillez. Para su uso utilizaremos también Cross Validation:
"""

# Cross-validation simple

folds = [3, 5, 7, 10]
model = LogisticRegression(max_iter=1000)

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')

for k in folds:
    cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)
    scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')

    print(f"{k} folds:")
    print(f"  Accuracy por fold: {scores}")
    print(f"  Accuracy media: {scores.mean():.4f}\n")

# Entrenamos modelo final
model.fit(X_train_scaled, y_train)
test_acc = model.score(X_test_scaled, y_test)

print("Accuracy final en test:", test_acc)

"""Como podemos observar, nuestro primer modelo de regresión logística obtiene una precisión media en el conjunto de entrenamiento de aproximadamente 92.8% según la validación cruzada. Al evaluar el modelo final en el conjunto de prueba, la precisión alcanza un 94.7%, lo que indica que el modelo generaliza muy bien y no muestra signos de sobreajuste (memorizacion).

También podemos observar que utilizar 5 folds ofrece un buen equilibrio entre obtener una estimación estable de la accuracy y no incrementar en exceso el número de particiones del conjunto de entrenamiento.

### Analizaremos este resultado calculando la recta ROC, PR y la matriz de confusion:
"""

# Convertimos y a formato binario (One-hot)
y_bin = label_binarize(y_test, classes=[0,1,2,3])
n_classes = y_bin.shape[1]

# Predicciones de probabilidades
y_score = model.predict_proba(X_test_scaled)  # lista de arrays por clase

# Para cada clase, dibujamos la curva Precision-Recall
plt.figure(figsize=(8,6))
for i in range(n_classes):
    precision, recall, _ = precision_recall_curve(y_bin[:, i], y_score[i][:,1] if y_score[i].ndim>1 else y_score[:, i])
    pr_auc = auc(recall, precision)
    plt.plot(recall, precision, label=f'Clase {i} (AUC={pr_auc:.2f})')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Curvas Precision-Recall (Multiclase)')
plt.legend()
plt.show()

# Binarizamos las clases
y_bin = label_binarize(y_test, classes=[0,1,2,3])
n_classes = y_bin.shape[1]

# Probabilidades predichas por el modelo
y_score = model.predict_proba(X_test_scaled)

# Dibujar ROC para cada clase
plt.figure(figsize=(8,6))
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_bin[:, i], y_score[i][:,1] if y_score[i].ndim>1 else y_score[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Clase {i} (AUC={roc_auc:.2f})')

plt.plot([0,1], [0,1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curvas ROC (Multiclase)')
plt.legend()
plt.show()

# Usar el modelo entrenado y los datos de prueba correctos
disp = ConfusionMatrixDisplay.from_estimator(
    model,
    X_test_scaled, # Usar datos de prueba ESCALADOS
    y_test,        # Usar etiquetas de prueba reales
    cmap=plt.cm.Blues,
    normalize=None
)

# Corregir el título a Multiclase
disp.ax_.set_title("Matriu de Confusió - Regressió Logística (Multiclase)")
plt.show()

"""Por lo general podemos ver que el modelo de Regresion logistica classifica de forma correcta la mayoria de casos.

### Por ultimo utilizaremos un classification_report para ver mejor la informacion:
"""

# Generar predicciones de clase
y_pred_test = model.predict(X_test_scaled)

report_log = classification_report(y_test, y_pred_test)
print(report_log)

"""## 7. RandomForest

"""

# Número de folds que queremos probar
folds = [3, 5, 7, 10]

# Modelo Random Forest
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Cross-validation para cada número de folds
for k in folds:
    cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)
    scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')

    print(f"{k} folds:")
    print(f"  Accuracy por fold: {scores}")
    print(f"  Accuracy media: {scores.mean():.4f}\n")

# Entrenamos modelo final sobre todo el set de entrenamiento
model.fit(X_train_scaled, y_train)
test_acc = model.score(X_test_scaled, y_test)

print("Accuracy final en test:", test_acc)

"""Como podemos observar, con 3 folds el modelo obtiene una precisión media de 85.5%, mientras que al aumentar a 5, 7 y 10 folds la precisión media mejora ligeramente, alcanzando aproximadamente 86.2–86.3%. La evaluación final en el conjunto de prueba muestra una precisión de 87.3%, lo que indica que el modelo generaliza correctamente y no presenta sobreajuste.

Además, utilizar un número intermedio de folds, como 5 o 7, ofrece un buen equilibrio entre obtener una estimación estable de la accuracy y no incrementar demasiado el número de particiones del conjunto de entrenamiento.

### Analizaremos este resultado calculando la recta ROC, PR y la matriz de confusion:
"""

# Convertimos y a formato binario (One-hot)
y_bin = label_binarize(y_test, classes=[0,1,2,3])
n_classes = y_bin.shape[1]

# Predicciones de probabilidades
y_score = model.predict_proba(X_test_scaled)  # lista de arrays por clase

# Para cada clase, dibujamos la curva Precision-Recall
plt.figure(figsize=(8,6))
for i in range(n_classes):
    precision, recall, _ = precision_recall_curve(y_bin[:, i], y_score[i][:,1] if y_score[i].ndim>1 else y_score[:, i])
    pr_auc = auc(recall, precision)
    plt.plot(recall, precision, label=f'Clase {i} (AUC={pr_auc:.2f})')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Curvas Precision-Recall (Multiclase)')
plt.legend()
plt.show()

# Binarizamos las clases
y_bin = label_binarize(y_test, classes=[0,1,2,3])
n_classes = y_bin.shape[1]

# Probabilidades predichas por el modelo
y_score = model.predict_proba(X_test_scaled)

# Dibujar ROC para cada clase
plt.figure(figsize=(8,6))
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_bin[:, i], y_score[i][:,1] if y_score[i].ndim>1 else y_score[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Clase {i} (AUC={roc_auc:.2f})')

plt.plot([0,1], [0,1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curvas ROC (Multiclase)')
plt.legend()
plt.show()

# Usar el modelo entrenado y los datos de prueba correctos
disp = ConfusionMatrixDisplay.from_estimator(
    model,
    X_test_scaled, # Usar datos de prueba ESCALADOS
    y_test,        # Usar etiquetas de prueba reales
    cmap=plt.cm.Blues,
    normalize=None
)

# Corregir el título a Multiclase
disp.ax_.set_title("Matriu de Confusió - Regressió Logística (Multiclase)")
plt.show()

# Generar predicciones de clase
y_pred_test = model.predict(X_test_scaled)

report_log = classification_report(y_test, y_pred_test)
print(report_log)

"""## 8. Gradient Boosting"""

# Número de folds que queremos probar
folds = [3, 5, 7, 10]

# Modelo Gradient Boosting
model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)

# Cross-validation para cada número de folds
for k in folds:
    cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)
    scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')

    print(f"{k} folds:")
    print(f"  Accuracy por fold: {scores}")
    print(f"  Accuracy media: {scores.mean():.4f}\n")

# Entrenamos modelo final sobre todo el set de entrenamiento
model.fit(X_train_scaled, y_train)
test_acc = model.score(X_test_scaled, y_test)

print("Accuracy final en test:", test_acc)

"""Como podemos observar, con 3 folds el modelo Gradient Boosting obtiene una precisión media de 86.5%, mientras que al aumentar a 5, 7 y 10 folds la precisión media mejora gradualmente, alcanzando aproximadamente 87.9–88.6%. La evaluación final en el conjunto de prueba muestra una precisión de 91%, lo que indica que el modelo generaliza correctamente y no presenta signos de sobreajuste.

Además, utilizar un número intermedio de folds, como 5 o 7, ofrece un buen equilibrio entre obtener una estimación estable de la accuracy y no incrementar demasiado el número de particiones del conjunto de entrenamiento.

### Analizaremos este resultado calculando la recta ROC, PR y la matriz de confusion:
"""

# Convertimos y a formato binario (One-hot)
y_bin = label_binarize(y_test, classes=[0,1,2,3])
n_classes = y_bin.shape[1]

# Predicciones de probabilidades
y_score = model.predict_proba(X_test_scaled)  # lista de arrays por clase

# Para cada clase, dibujamos la curva Precision-Recall
plt.figure(figsize=(8,6))
for i in range(n_classes):
    precision, recall, _ = precision_recall_curve(y_bin[:, i], y_score[i][:,1] if y_score[i].ndim>1 else y_score[:, i])
    pr_auc = auc(recall, precision)
    plt.plot(recall, precision, label=f'Clase {i} (AUC={pr_auc:.2f})')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Curvas Precision-Recall (Multiclase)')
plt.legend()
plt.show()

# Binarizamos las clases
y_bin = label_binarize(y_test, classes=[0,1,2,3])
n_classes = y_bin.shape[1]

# Probabilidades predichas por el modelo
y_score = model.predict_proba(X_test_scaled)

# Dibujar ROC para cada clase
plt.figure(figsize=(8,6))
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_bin[:, i], y_score[i][:,1] if y_score[i].ndim>1 else y_score[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Clase {i} (AUC={roc_auc:.2f})')

plt.plot([0,1], [0,1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curvas ROC (Multiclase)')
plt.legend()
plt.show()

# Usar el modelo entrenado y los datos de prueba correctos
disp = ConfusionMatrixDisplay.from_estimator(
    model,
    X_test_scaled, # Usar datos de prueba ESCALADOS
    y_test,        # Usar etiquetas de prueba reales
    cmap=plt.cm.Blues,
    normalize=None
)

# Corregir el título a Multiclase
disp.ax_.set_title("Matriu de Confusió - Regressió Logística (Multiclase)")
plt.show()

# Generar predicciones de clase
y_pred_test = model.predict(X_test_scaled)

report_log = classification_report(y_test, y_pred_test)
print(report_log)

"""## 9. Analisis final

"""

report_log = classification_report(y_test, y_pred_test)
print(report_log)
